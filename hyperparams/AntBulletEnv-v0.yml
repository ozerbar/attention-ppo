AntBulletEnv-v0:
  n_timesteps: 2_000_000
  n_envs: 16
  env_wrapper: "wrappers.ant_bullet_env_v0.wrap_ant"

  batch_size: 128
  n_steps: 512
  n_epochs: 20
  gamma: 0.99
  gae_lambda: 0.9
  clip_range: "constant_0.4"
  ent_coef: 0.0
  vf_coef: 0.5
  max_grad_norm: 0.5
  learning_rate: "constant_3e-5"
  use_sde: true
  sde_sample_freq: 4

  normalize: true  # keep this only
  # remove normalize_kwargs completely

  policy: "MlpPolicy"
  policy_kwargs: >
    dict(log_std_init=-1, ortho_init=False, activation_fn=nn.ReLU,
         net_arch=[dict(pi=[256, 256], vf=[256, 256])])
