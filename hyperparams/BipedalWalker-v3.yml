BipedalWalker-v3:
  normalize: true
  n_envs: 32
  n_timesteps: !!float 5e6
  policy: 'MlpPolicy'
  n_steps: 2048
  batch_size: 64
  gae_lambda: 0.95
  gamma: 0.999
  n_epochs: 10
  ent_coef: 0.0
  env_wrapper: sb3_contrib.common.wrappers.TimeFeatureWrapper
  learning_rate: !!float 3e-4
  clip_range: 0.18
  policy: "MlpPolicy"
  policy_kwargs: >
    dict(log_std_init=-1, ortho_init=False, activation_fn=nn.ReLU,
         net_arch=dict(pi=[256, 256], vf=[256, 256]))